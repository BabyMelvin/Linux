**时间信息用于实现多媒体同步**。

同步的目的在于展示多媒体信息时，能够保持媒体对象之间固有的时间关系。同步有两类：

* 一类是流内同步，其主要任务是保证单个媒体流内的时间关系，以满足感知要求，如按照规定的帧率播放一段视频；
* 另一类是流间同步，主要任务是保证不同媒体流之间的时间关系，如音频和视频之间的关系（lipsync）。

对于固定速率的媒体，如固定帧率的视频或固定比特率的音频，可以将时间信息（帧率或比特率）置于文件首部（header），如`AVI`的`hdrl List`、`MP4`的`moov box`，还有一种相对复杂的方案是将时间信息嵌入媒体流的内部，如`MPEG TS`和`Real video`，这种方案可以处理变速率的媒体，亦可有效避免同步过程中的时间漂移。

FFMPEG会为每一个数据包打上时间标签，以更有效地支持上层应用的同步机制。时间标签有两种，一种是DTS，称为解码时间标签，另一种是PTS，称为显示时间标签。对于声音来说 ，这两个时间标签是相同的，但对于某些视频编码格式，由于采用了双向预测技术，会造成DTS和PTS的不一致。

无双向预测帧的情况：
```
图像类型: I   P   P   P   P   P   P ...  I   P   P
DTS:     0   1   2   3   4   5   6...  100 101 102
PTS:     0   1   2   3   4   5   6...  100 101 102

有双向预测帧的情况：
图像类型: I   P   B   B   P   B   B ...  I   P   B
DTS:     0   1   2   3   4   5   6 ...  100 101 102
PTS:     0   3   1   2   6   4   5 ...  100 104 102
对于存在双向预测帧的情况，通常要求解码器对图像重排序，以保证输出的图像顺序为显示顺序：
解码器输入：I   P   B   B   P   B   B
 (DTS)     0   1   2   3   4   5   6  
 (PTS)     0   3   1   2   6   4   5
解码器输出：X   I   B   B   P   B   B   P
 (PTS)     X   0   1   2   3   4   5   6
```

### 时间信息的获取

通过调用`avformat_find_stream_info`，多媒体应用可以从`AVFormatContext`对象中拿到媒体文件的时间信息：主要是总时间长度和开始时间，此外还有与时间信息相关的比特率和文件大小。其中时间信息的单位是`AV_TIME_BASE`：微秒。

```c
typedef struct AVFormatContext {
    / **解码元件的第一帧的位置，在
       AV_TIME_BASE分数秒。从来没有设置这个值直接：
       推导的AVStream值。 * /
    int64_t start_time;
    / **解码流的时间，在AV_TIME_BASE分数秒。只设置这个值，如果你知道没有个人流工期，也不要设置任何他们。这是从推导AVStream值如果没有设置。 * /
    int64_t duration;
    / **解码：总的文件大小，如果未知=0* /
    int64_t file_size;
    / **解码：在比特/秒的总流率，如果不可用。从来没有直接设置它如果得到file_size和时间是已知的如FFmpeg的自动计算。 * /
    int bit_rate;
    .....
} AVFormatContext;
```
以上4个成员变量都是只读的，基于FFMpeg的中间件需要将其封装到某个接口中，如：
* `LONG GetDuratioin(IntfX*);`
* `LONG GetStartTime(IntfX*);`
* `LONG GetFileSize(IntfX*);`
* `LONG GetBitRate(IntfX*); `
